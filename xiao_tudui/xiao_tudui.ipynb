{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install PyTorch, per the instruction: https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if PyTorch uses GPU; if not, try: \\\n",
    "&emsp; 1. PyTorch only uses NVDIA, check if NVDIA in Task Manager -> Performance -> GPU \\\n",
    "&emsp; 2. If YES to 1, try command \"nvidia-smi\" to see driver version \\\n",
    "&emsp; 3. If too low, download and update driver from NVDIA website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two commonly-used functions: \\\n",
    "&emsp; 1. dir(torch) \\\n",
    "&emsp; 2. help(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_available in module torch.cuda:\n",
      "\n",
      "is_available() -> bool\n",
      "    Returns a bool indicating if CUDA is currently available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir(torch.cuda.is_available)\n",
    "help(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch, to load datasets: \\\n",
    "&emsp; 1. Dataset: Provide a way to collect data and its label; \\\n",
    "&emsp; 2. Dataloader: Provide different data format for networks; \\\n",
    "&emsp; 3. Sample Datasets Download: https://download.pytorch.org/tutorial/hymenoptera_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create class MyData from Dataset, overwritting __init__ & __getitem__\n",
    "\"\"\"\n",
    "class MyData(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, train_val_dir, label_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.train_val_dir = train_val_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.path = os.path.join(self.root_dir, self.train_val_dir, self.label_dir)\n",
    "        self.img_path = os.listdir(self.path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.img_path[index]\n",
    "        img_item_path = os.path.join(self.root_dir, self.train_val_dir, self.label_dir, img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir\n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train - Ants\n",
    "\"\"\"\n",
    "root_dir = \"C:\\\\Hunting\\\\2023\\\\data_personal\\\\hymenoptera\"\n",
    "train_val_dir = \"train\"\n",
    "label_dir = \"ants\"\n",
    "ants = MyData(root_dir=root_dir,train_val_dir=train_val_dir, label_dir=label_dir)\n",
    "img, label = ants[0]\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train - Bees\n",
    "\"\"\"\n",
    "root_dir = \"C:\\\\Hunting\\\\2023\\\\data_personal\\\\hymenoptera\"\n",
    "train_val_dir = \"train\"\n",
    "label_dir = \"bees\"\n",
    "bees = MyData(root_dir=root_dir,train_val_dir=train_val_dir, label_dir=label_dir)\n",
    "img, label = bees[0]\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ants + bees\n",
    "train_dataset[123][0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard - Display Images \\\n",
    "&emsp; 1. tensorboard --logdir=logs --port=6007 \\\n",
    "&emsp; 2. used for training loss display - One image per step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"logs\")\n",
    "# writer.add_image()\n",
    "for i in range(100):\n",
    "    writer.add_scalar(\"y=x\", i, i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of Image: <class 'numpy.ndarray'>\n",
      "Shape of Image: (512, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "img, label = ants[0]\n",
    "img_array = np.array(img)\n",
    "print(f\"Type of Image: {type(img_array)}\")\n",
    "print(f\"Shape of Image: {img_array.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"logs\")\n",
    "writer.add_image(\"test\", img_array, 1, dataformats='HWC')\n",
    "for i in range(100):\n",
    "    writer.add_scalar(\"y=2x\", 2*i, i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform - Image Reformat \\\n",
    "&emsp; 1. ToTensor(object): a ''PIL Image'' or ''numpy.ndarray'' to tensor \\\n",
    "&emsp; &emsp; 1.1 How to use tranforms \\\n",
    "&emsp; &emsp; 1.2 Why need Tensor data structure \\\n",
    "&emsp; 2. Normalize \\\n",
    "&emsp; 3. Resize \\\n",
    "&emsp; 4. Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([3, 512, 768])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "PIL Image\n",
    "\"\"\"\n",
    "tensor_trains = transforms.ToTensor()\n",
    "tensor_img = tensor_trains(img)\n",
    "print(type(tensor_img))\n",
    "print(tensor_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_image(\"Tensor_img\", tensor_img)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Normalize\n",
    "\"\"\"\n",
    "trans_norms = transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "img_norms = trans_norms(tensor_img)\n",
    "writer.add_image(\"Tensor_img_norm\", img_norms)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resize\n",
    "\"\"\"\n",
    "trans_resize = transforms.Resize((512, 512))\n",
    "img_resize = trans_resize(img)\n",
    "img_resize = tensor_trains(img_resize)\n",
    "writer.add_image(\"Tensor_img_resize\", img_resize)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compose - resie - 2\n",
    "\"\"\"\n",
    "trans_resize_2 = transforms.Resize(512)\n",
    "trans_compose = transforms.Compose([trans_resize_2, tensor_trains])\n",
    "img_resize_2 = trans_compose(img)\n",
    "# img_resize = tensor_trains(img_resize)\n",
    "writer.add_image(\"Tensor_img_resize_2\", img_resize_2)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchvision of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\Hunting\\2023\\data_personal\\hymenoptera\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Hunting\\2023\\data_personal\\hymenoptera\\cifar-10-python.tar.gz to C:\\Hunting\\2023\\data_personal\\hymenoptera\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = datasets.CIFAR10(root=root_dir, train=True, download=True)\n",
    "test_set = datasets.CIFAR10(root=root_dir, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(test_set.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to C:\\Hunting\\2023\\data_personal\\hymenoptera\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting C:\\Hunting\\2023\\data_personal\\hymenoptera\\cifar-10-python.tar.gz to C:\\Hunting\\2023\\data_personal\\hymenoptera\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_set = datasets.CIFAR10(root=root_dir, train=True, transform=dataset_transform, download=True)\n",
    "test_set = datasets.CIFAR10(root=root_dir, train=False, transform=dataset_transform, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset=test_set, batch_size=4, shuffle=True, num_workers=0, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):\n",
    "    step = 0\n",
    "    for data in test_loader:\n",
    "        imgs, targets = data\n",
    "        # print(imgs.shape)\n",
    "        # print(targets)\n",
    "        writer.add_images(\"test_data\", imgs, step)\n",
    "        step += 1\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
